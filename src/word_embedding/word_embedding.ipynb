{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delimiter='$'\n",
    "columns = ['first_char_id', 'second_char_id', 'movie_id', 'source_sentence', 'target_sentence']\n",
    "source_df = pd.read_csv('../../data/cornell_corpus/clean_data.csv',delimiter=delimiter,names=columns,skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_char_id</th>\n",
       "      <th>second_char_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>source_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
       "      <td>Seems like she could get a date easy enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Why?</td>\n",
       "      <td>Unsolved mystery.  She used to be really popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Unsolved mystery.  She used to be really popul...</td>\n",
       "      <td>That's a shame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>C'esc ma tete. This is my head</td>\n",
       "      <td>Right.  See?  You're ready for the quiz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Right.  See?  You're ready for the quiz.</td>\n",
       "      <td>I don't want to know how to say that though.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>I don't want to know how to say that though.  ...</td>\n",
       "      <td>That's because it's such a nice one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>That's because it's such a nice one.</td>\n",
       "      <td>Forget French.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>How is our little Find the Wench A Date plan p...</td>\n",
       "      <td>Well, there's someone I think might be --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>There.</td>\n",
       "      <td>Where?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>You got something on your mind?</td>\n",
       "      <td>I counted on you to help my cause. You and tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>You have my word.  As a gentleman</td>\n",
       "      <td>You're sweet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>How do you get your hair to look like that?</td>\n",
       "      <td>Eber's Deep Conditioner every two days. And I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Sure have.</td>\n",
       "      <td>I really, really, really wanna go, but I can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>I really, really, really wanna go, but I can't...</td>\n",
       "      <td>I'm workin' on it. But she doesn't seem to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>She's not a...</td>\n",
       "      <td>Lesbian?  No. I found a picture of Jared Leto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Lesbian?  No. I found a picture of Jared Leto ...</td>\n",
       "      <td>So that's the kind of guy she likes? Pretty ones?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>So that's the kind of guy she likes? Pretty ones?</td>\n",
       "      <td>Who knows?  All I've ever heard her say is tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Looks like things worked out tonight, huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>You know Chastity?</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Have fun tonight?</td>\n",
       "      <td>Tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>I looked for you back at the party, but you al...</td>\n",
       "      <td>I was?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>I was?</td>\n",
       "      <td>You never wanted to go out with 'me, did you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>Well, no...</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221586</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>Sikali Horse, My Lord. Christians alL I know e...</td>\n",
       "      <td>They come well recommended do they? DURNFORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221587</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>Oh... indeed. Crealock, we should see that Col...</td>\n",
       "      <td>I thought it might be more effective to find s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221588</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>Excellent. Thank you.  Give them to Crealock, ...</td>\n",
       "      <td>My Lord.  This list was prepared for you. I do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221589</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>You intended to bring your reserves across the...</td>\n",
       "      <td>I have received intelligence from, sources of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221590</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>I have received intelligence from, sources of ...</td>\n",
       "      <td>Intelligence? Sources of your own? Did it not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221591</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>Are you dictating the strategy of this war, Sir?</td>\n",
       "      <td>I'm explaining my reasons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221592</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9030</td>\n",
       "      <td>m616</td>\n",
       "      <td>Tomorrow we will continue our advance on Ulund...</td>\n",
       "      <td>And the threat of counter invasion no longer e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221593</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>Yes. I see you've issued each of them with a M...</td>\n",
       "      <td>But will they make good use of them?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221594</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>What's that strange name the newspaper chap's ...</td>\n",
       "      <td>Er, called Noggs, Sir Actual name is Norris-Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221595</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>Er, called Noggs, Sir Actual name is Norris-Ne...</td>\n",
       "      <td>Our runners bare his dispatches, do they not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221596</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>The only reports of enemy activity have come f...</td>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221597</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>Yes?</td>\n",
       "      <td>A large party of Zulus have been sighted in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221598</th>\n",
       "      <td>u9027</td>\n",
       "      <td>u9029</td>\n",
       "      <td>m616</td>\n",
       "      <td>Splendid site, Crealock, splendil I want to es...</td>\n",
       "      <td>Certainly, Sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221599</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>Stuart?</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221600</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>How quickly can you move your artillery forward?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221601</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>How quickly can you move your artillery forward?</td>\n",
       "      <td>Well, my horses are feeding, as you may observ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221602</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>Well, my horses are feeding, as you may observ...</td>\n",
       "      <td>Well, fed or hungry, Pulleine wants them in po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221603</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9033</td>\n",
       "      <td>m616</td>\n",
       "      <td>Well, fed or hungry, Pulleine wants them in po...</td>\n",
       "      <td>Right.  Bombardier, to me please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221604</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Lighting COGHILL' 5 cigar: Our good Colonel Du...</td>\n",
       "      <td>Um. There are rumours that my Lord Chelmsford ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221605</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Um. There are rumours that my Lord Chelmsford ...</td>\n",
       "      <td>Well that's typical of Her Majesty's army. App...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221606</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Do you think she might be interested in  someone?</td>\n",
       "      <td>Which one?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221607</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Which one?</td>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221608</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221609</th>\n",
       "      <td>u9028</td>\n",
       "      <td>u9031</td>\n",
       "      <td>m616</td>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221610</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221611</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221612</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221613</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>I think Chelmsford wants a good man on the bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221614</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>Well I assure you, Sir, I have no desire to cr...</td>\n",
       "      <td>And I assure you, you do not In fact I'd be ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221615</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>And I assure you, you do not In fact I'd be ob...</td>\n",
       "      <td>So far only their scouts. But we have had repo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_char_id second_char_id movie_id  \\\n",
       "0                 u0             u2       m0   \n",
       "1                 u0             u2       m0   \n",
       "2                 u0             u2       m0   \n",
       "3                 u0             u2       m0   \n",
       "4                 u0             u2       m0   \n",
       "5                 u0             u2       m0   \n",
       "6                 u0             u2       m0   \n",
       "7                 u0             u2       m0   \n",
       "8                 u0             u2       m0   \n",
       "9                 u0             u2       m0   \n",
       "10                u0             u2       m0   \n",
       "11                u0             u2       m0   \n",
       "12                u0             u2       m0   \n",
       "13                u0             u2       m0   \n",
       "14                u0             u2       m0   \n",
       "15                u0             u2       m0   \n",
       "16                u0             u2       m0   \n",
       "17                u0             u2       m0   \n",
       "18                u0             u2       m0   \n",
       "19                u0             u2       m0   \n",
       "20                u0             u2       m0   \n",
       "21                u0             u2       m0   \n",
       "22                u0             u2       m0   \n",
       "23                u0             u2       m0   \n",
       "24                u0             u2       m0   \n",
       "25                u0             u2       m0   \n",
       "26                u0             u2       m0   \n",
       "27                u0             u2       m0   \n",
       "28                u0             u2       m0   \n",
       "29                u0             u2       m0   \n",
       "...              ...            ...      ...   \n",
       "221586         u9027          u9030     m616   \n",
       "221587         u9027          u9030     m616   \n",
       "221588         u9027          u9030     m616   \n",
       "221589         u9027          u9030     m616   \n",
       "221590         u9027          u9030     m616   \n",
       "221591         u9027          u9030     m616   \n",
       "221592         u9027          u9030     m616   \n",
       "221593         u9027          u9029     m616   \n",
       "221594         u9027          u9029     m616   \n",
       "221595         u9027          u9029     m616   \n",
       "221596         u9027          u9029     m616   \n",
       "221597         u9027          u9029     m616   \n",
       "221598         u9027          u9029     m616   \n",
       "221599         u9028          u9033     m616   \n",
       "221600         u9028          u9033     m616   \n",
       "221601         u9028          u9033     m616   \n",
       "221602         u9028          u9033     m616   \n",
       "221603         u9028          u9033     m616   \n",
       "221604         u9028          u9031     m616   \n",
       "221605         u9028          u9031     m616   \n",
       "221606         u9028          u9031     m616   \n",
       "221607         u9028          u9031     m616   \n",
       "221608         u9028          u9031     m616   \n",
       "221609         u9028          u9031     m616   \n",
       "221610         u9030          u9034     m616   \n",
       "221611         u9030          u9034     m616   \n",
       "221612         u9030          u9034     m616   \n",
       "221613         u9030          u9034     m616   \n",
       "221614         u9030          u9034     m616   \n",
       "221615         u9030          u9034     m616   \n",
       "\n",
       "                                          source_sentence  \\\n",
       "0       Can we make this quick?  Roxanne Korrine and A...   \n",
       "1       Well, I thought we'd start with pronunciation,...   \n",
       "2       Not the hacking and gagging and spitting part....   \n",
       "3       You're asking me out.  That's so cute. What's ...   \n",
       "4       No, no, it's my fault -- we didn't have a prop...   \n",
       "5                                                Cameron.   \n",
       "6       The thing is, Cameron -- I'm at the mercy of a...   \n",
       "7                                                    Why?   \n",
       "8       Unsolved mystery.  She used to be really popul...   \n",
       "9          Gosh, if only we could find Kat a boyfriend...   \n",
       "10                         C'esc ma tete. This is my head   \n",
       "11               Right.  See?  You're ready for the quiz.   \n",
       "12      I don't want to know how to say that though.  ...   \n",
       "13                   That's because it's such a nice one.   \n",
       "14      How is our little Find the Wench A Date plan p...   \n",
       "15                                                 There.   \n",
       "16                        You got something on your mind?   \n",
       "17                      You have my word.  As a gentleman   \n",
       "18            How do you get your hair to look like that?   \n",
       "19                                             Sure have.   \n",
       "20      I really, really, really wanna go, but I can't...   \n",
       "21                                         She's not a...   \n",
       "22      Lesbian?  No. I found a picture of Jared Leto ...   \n",
       "23      So that's the kind of guy she likes? Pretty ones?   \n",
       "24                                                    Hi.   \n",
       "25                                     You know Chastity?   \n",
       "26                                      Have fun tonight?   \n",
       "27      I looked for you back at the party, but you al...   \n",
       "28                                                 I was?   \n",
       "29                                            Well, no...   \n",
       "...                                                   ...   \n",
       "221586  Sikali Horse, My Lord. Christians alL I know e...   \n",
       "221587  Oh... indeed. Crealock, we should see that Col...   \n",
       "221588  Excellent. Thank you.  Give them to Crealock, ...   \n",
       "221589  You intended to bring your reserves across the...   \n",
       "221590  I have received intelligence from, sources of ...   \n",
       "221591   Are you dictating the strategy of this war, Sir?   \n",
       "221592  Tomorrow we will continue our advance on Ulund...   \n",
       "221593  Yes. I see you've issued each of them with a M...   \n",
       "221594  What's that strange name the newspaper chap's ...   \n",
       "221595  Er, called Noggs, Sir Actual name is Norris-Ne...   \n",
       "221596  The only reports of enemy activity have come f...   \n",
       "221597                                               Yes?   \n",
       "221598  Splendid site, Crealock, splendil I want to es...   \n",
       "221599                                            Stuart?   \n",
       "221600                                               Yes.   \n",
       "221601   How quickly can you move your artillery forward?   \n",
       "221602  Well, my horses are feeding, as you may observ...   \n",
       "221603  Well, fed or hungry, Pulleine wants them in po...   \n",
       "221604  Lighting COGHILL' 5 cigar: Our good Colonel Du...   \n",
       "221605  Um. There are rumours that my Lord Chelmsford ...   \n",
       "221606  Do you think she might be interested in  someone?   \n",
       "221607                                         Which one?   \n",
       "221608    Well that one. The one who keeps looking at me.   \n",
       "221609  Choose your targets men. That's right Watch th...   \n",
       "221610  Colonel Durnford... William Vereker. I hear yo...   \n",
       "221611                           Your orders, Mr Vereker?   \n",
       "221612  I'm to take the Sikali with the main column to...   \n",
       "221613  Lord Chelmsford seems to want me to stay back ...   \n",
       "221614  Well I assure you, Sir, I have no desire to cr...   \n",
       "221615  And I assure you, you do not In fact I'd be ob...   \n",
       "\n",
       "                                          target_sentence  \n",
       "0       Well, I thought we'd start with pronunciation,...  \n",
       "1       Not the hacking and gagging and spitting part....  \n",
       "2       Okay... then how 'bout we try out some French ...  \n",
       "3                                              Forget it.  \n",
       "4                                                Cameron.  \n",
       "5       The thing is, Cameron -- I'm at the mercy of a...  \n",
       "6          Seems like she could get a date easy enough...  \n",
       "7       Unsolved mystery.  She used to be really popul...  \n",
       "8                                         That's a shame.  \n",
       "9                               Let me see what I can do.  \n",
       "10               Right.  See?  You're ready for the quiz.  \n",
       "11      I don't want to know how to say that though.  ...  \n",
       "12                   That's because it's such a nice one.  \n",
       "13                                         Forget French.  \n",
       "14              Well, there's someone I think might be --  \n",
       "15                                                 Where?  \n",
       "16      I counted on you to help my cause. You and tha...  \n",
       "17                                          You're sweet.  \n",
       "18      Eber's Deep Conditioner every two days. And I ...  \n",
       "19      I really, really, really wanna go, but I can't...  \n",
       "20      I'm workin' on it. But she doesn't seem to be ...  \n",
       "21      Lesbian?  No. I found a picture of Jared Leto ...  \n",
       "22      So that's the kind of guy she likes? Pretty ones?  \n",
       "23      Who knows?  All I've ever heard her say is tha...  \n",
       "24             Looks like things worked out tonight, huh?  \n",
       "25                   I believe we share an art instructor  \n",
       "26                                                   Tons  \n",
       "27                                                 I was?  \n",
       "28          You never wanted to go out with 'me, did you?  \n",
       "29                        Then that's all you had to say.  \n",
       "...                                                   ...  \n",
       "221586       They come well recommended do they? DURNFORD  \n",
       "221587  I thought it might be more effective to find s...  \n",
       "221588  My Lord.  This list was prepared for you. I do...  \n",
       "221589  I have received intelligence from, sources of ...  \n",
       "221590  Intelligence? Sources of your own? Did it not ...  \n",
       "221591                         I'm explaining my reasons.  \n",
       "221592  And the threat of counter invasion no longer e...  \n",
       "221593               But will they make good use of them?  \n",
       "221594  Er, called Noggs, Sir Actual name is Norris-Ne...  \n",
       "221595      Our runners bare his dispatches, do they not?  \n",
       "221596                                         Thank you.  \n",
       "221597  A large party of Zulus have been sighted in th...  \n",
       "221598                                     Certainly, Sin  \n",
       "221599                                               Yes.  \n",
       "221600   How quickly can you move your artillery forward?  \n",
       "221601  Well, my horses are feeding, as you may observ...  \n",
       "221602  Well, fed or hungry, Pulleine wants them in po...  \n",
       "221603                  Right.  Bombardier, to me please.  \n",
       "221604  Um. There are rumours that my Lord Chelmsford ...  \n",
       "221605  Well that's typical of Her Majesty's army. App...  \n",
       "221606                                         Which one?  \n",
       "221607    Well that one. The one who keeps looking at me.  \n",
       "221608  ft could be you flatter yourself CoghilL It's ...  \n",
       "221609  Keep steady. You're the best shots of the Twen...  \n",
       "221610  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n",
       "221611  I'm to take the Sikali with the main column to...  \n",
       "221612  Lord Chelmsford seems to want me to stay back ...  \n",
       "221613  I think Chelmsford wants a good man on the bor...  \n",
       "221614  And I assure you, you do not In fact I'd be ob...  \n",
       "221615  So far only their scouts. But we have had repo...  \n",
       "\n",
       "[221616 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(source_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentence Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['choose', 'your', 'targets', 'men', 'thats', 'right', 'watch', 'for', 'you', 'good']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# This function is used to remove punctuation, espace in each sentence, and do the tokenization\n",
    "def clean_and_tokenization(sentence):\n",
    "    if not sentence or sentence == '':\n",
    "        return\n",
    "    \n",
    "    clean_sentence = \"\".join(char for char in str(sentence).strip().lower() if char not in string.punctuation)\n",
    "    \n",
    "    return clean_sentence.split(' ')\n",
    "\n",
    "\n",
    "# Unit test\n",
    "sentence = \"   Choose your targets men. That's right Watch for you good!!   \"\n",
    "print(clean_and_tokenization(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we use this function to get word list first\n",
    "\n",
    "word_list = []\n",
    "for row in source_df.iterrows():\n",
    "    try: \n",
    "        series = row[1]\n",
    "        \n",
    "        source_sentence = series['source_sentence']\n",
    "        target_sentence = series['target_sentence']\n",
    "        \n",
    "        source_words = clean_and_tokenization(source_sentence)\n",
    "        target_words = clean_and_tokenization(target_sentence)\n",
    "        \n",
    "        word_list.extend(source_words)\n",
    "        word_list.extend(target_words)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set = list(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 4749484\n",
      "Unique words: 66501\n"
     ]
    }
   ],
   "source": [
    "# To know the metrics\n",
    "\n",
    "print(\"Total words: {}\".format(len(word_list)))\n",
    "print(\"Unique words: {}\".format(len(word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'flatlines',\n",
       " 'nonot',\n",
       " 'winder',\n",
       " 'interdimensional',\n",
       " 'any',\n",
       " 'thisthere',\n",
       " 'cargo',\n",
       " 'switchin',\n",
       " 'rustlers',\n",
       " 'cheery',\n",
       " 'strangeits',\n",
       " 'rass',\n",
       " 'grassi',\n",
       " 'chink',\n",
       " 'valet',\n",
       " 'mmmmmmmmmm',\n",
       " 'virgins',\n",
       " 'backtrack',\n",
       " 'thug',\n",
       " 'inplease',\n",
       " 'rode',\n",
       " 'bowdoin',\n",
       " 'thorwalds',\n",
       " 'room�s']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check content\n",
    "\n",
    "word_set[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64338\n",
      "respected\n"
     ]
    }
   ],
   "source": [
    "# Create word to int dic and int to word dic\n",
    "\n",
    "word_to_int={}\n",
    "int_to_word={}\n",
    "index = 1\n",
    "\n",
    "for word in word_set:\n",
    "    word_to_int[word] = index\n",
    "    int_to_word[str(index)] = word\n",
    "    \n",
    "    index = index+1\n",
    "\n",
    "\n",
    "### Quick test\n",
    "\n",
    "print(word_to_int['stay'])\n",
    "print(int_to_word['4791'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = len(int_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the word list to index list using the word_to_int dictionary\n",
    "\n",
    "word_index_list = [word_to_int[word] for word in word_list]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some words like 'a', 'the', 'this' has no significant meaning, should remove them from word list in order to gain a better preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "threshold=1e-5\n",
    "word_counts = Counter(word_index_list)\n",
    "total_count = len(word_index_list)\n",
    "\n",
    "frequence = {word: count/total_count for word, count in word_counts.items()}\n",
    "drop_prob = {word: 1 - np.sqrt(threshold / frequence[word]) for word in word_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a random to decide if we pick a word into training word\n",
    "import random\n",
    "\n",
    "trainning_word_index_list=[word for word in word_index_list if random.random() < (1 - drop_prob[word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick\n",
      "roxanne\n",
      "korrine\n",
      "barrett\n",
      "incredibly\n",
      "horrendous\n",
      "public\n",
      "break\n",
      "quad\n",
      "wed\n",
      "pronunciation\n",
      "pronunciation\n",
      "hacking\n",
      "gagging\n",
      "spitting\n",
      "part\n",
      "hacking\n",
      "gagging\n",
      "spitting\n",
      "cuisine\n",
      "saturday\n",
      "night\n",
      "asking\n",
      "cute\n",
      "proper\n",
      "introduction\n",
      "cameron\n",
      "cameron\n",
      "cameron\n",
      "mercy\n"
     ]
    }
   ],
   "source": [
    "# An unit test\n",
    "\n",
    "test_list = trainning_word_index_list[:30]\n",
    "\n",
    "for index in test_list:\n",
    "    print(int_to_word[str(index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data into small batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we should make data into small batches in order to use skip-gram model\n",
    "\n",
    "# The batch size C is the size of training context, if c is larger, normally we can extract more patterns. But the sarcrifice is training time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input word is shed\n",
      "The target words are: \n",
      "dating\n",
      "pretty\n",
      "dip\n",
      "likes\n",
      "smokes\n"
     ]
    }
   ],
   "source": [
    "# First thing, should have a function to get target words\n",
    "\n",
    "def get_target_words(word_index_list, index, window_size=5):\n",
    "    \n",
    "    R = np.random.randint(1, window_size+1)\n",
    "    \n",
    "    start = index - R if (index - R) > 0 else 0\n",
    "    end = index + R\n",
    "    \n",
    "    target_word_indexes = set(word_index_list[start: index] + word_index_list[index+1: end+1])\n",
    "    \n",
    "    return target_word_indexes\n",
    "\n",
    "\n",
    "# A quick unit test\n",
    "index = 125\n",
    "print('The input word is {}'.format(int_to_word[str(trainning_word_index_list[index])]))\n",
    "\n",
    "print('The target words are: ')\n",
    "for target in get_target_words(trainning_word_index_list, index, 5):\n",
    "    print(int_to_word[str(target)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x, bath length is 52\n",
      "quick\n",
      "quick\n",
      "quick\n",
      "quick\n",
      "quick\n",
      "roxanne\n",
      "roxanne\n",
      "roxanne\n",
      "roxanne\n",
      "korrine\n",
      "korrine\n",
      "korrine\n",
      "korrine\n",
      "korrine\n",
      "korrine\n",
      "korrine\n",
      "barrett\n",
      "barrett\n",
      "barrett\n",
      "barrett\n",
      "barrett\n",
      "barrett\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "incredibly\n",
      "horrendous\n",
      "horrendous\n",
      "horrendous\n",
      "horrendous\n",
      "horrendous\n",
      "horrendous\n",
      "public\n",
      "public\n",
      "public\n",
      "public\n",
      "break\n",
      "break\n",
      "break\n",
      "break\n",
      "break\n",
      "quad\n",
      "quad\n",
      "quad\n",
      "quad\n",
      "wed\n",
      "wed\n",
      "***************\n",
      "input y, bath lenght is 52\n",
      "barrett\n",
      "horrendous\n",
      "incredibly\n",
      "roxanne\n",
      "korrine\n",
      "korrine\n",
      "barrett\n",
      "incredibly\n",
      "quick\n",
      "barrett\n",
      "break\n",
      "horrendous\n",
      "incredibly\n",
      "public\n",
      "roxanne\n",
      "quick\n",
      "quick\n",
      "horrendous\n",
      "incredibly\n",
      "public\n",
      "roxanne\n",
      "korrine\n",
      "wed\n",
      "barrett\n",
      "break\n",
      "quick\n",
      "horrendous\n",
      "public\n",
      "roxanne\n",
      "quad\n",
      "korrine\n",
      "barrett\n",
      "break\n",
      "incredibly\n",
      "public\n",
      "quad\n",
      "korrine\n",
      "horrendous\n",
      "incredibly\n",
      "quad\n",
      "break\n",
      "wed\n",
      "horrendous\n",
      "incredibly\n",
      "public\n",
      "quad\n",
      "horrendous\n",
      "public\n",
      "wed\n",
      "break\n",
      "quad\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# Then we try to make the training index word list into samll batches\n",
    "\n",
    "def get_batches(word_index_list, batch_size, window_size=5):\n",
    "    n_batches = len(word_index_list) //batch_size\n",
    "    \n",
    "    # We keep only the n_batches of data\n",
    "    rest_word_index_list = word_index_list[:batch_size * n_batches]\n",
    "    \n",
    "    for idx in range(0, len(word_index_list), batch_size):\n",
    "        x, y =[],[]\n",
    "        \n",
    "        batch = word_index_list[idx:idx+batch_size]\n",
    "        \n",
    "        for ii in range(len(batch)):\n",
    "            batch_x = batch[ii]\n",
    "            batch_y = get_target_words(batch, ii, window_size)\n",
    "            \n",
    "            y.extend(batch_y)\n",
    "            x.extend([batch_x] * len(batch_y))\n",
    "        \n",
    "        yield x,y\n",
    "        \n",
    "    \n",
    "\n",
    "# A quick unit test for this function\n",
    "\n",
    "test_list = trainning_word_index_list[:100]\n",
    "batch_size =10\n",
    "\n",
    "for x, y  in get_batches(test_list, batch_size):\n",
    "    print(\"input x, bath length is {}\".format(len(x)))\n",
    "    for x_in in x:\n",
    "        print(int_to_word[str(x_in)])\n",
    "        \n",
    "    \n",
    "    print(\"***************\")    \n",
    "        \n",
    "    print(\"input y, bath lenght is {}\".format(len(y)))\n",
    "    for y_in in y:\n",
    "        print(int_to_word[str(y_in)])\n",
    "    \n",
    "    break\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training data is 909014\n"
     ]
    }
   ],
   "source": [
    "# The length of training data\n",
    "\n",
    "print(\"The length of training data is {0}\".format(len(trainning_word_index_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the tensorflow to train the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the graph\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "train_graph = tf.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "\n",
    "with train_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, [None], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name = \"labels\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define embedding layer\n",
    "\n",
    "num_words = len(int_to_word)\n",
    "num_embedding = 200\n",
    "\n",
    "with train_graph.as_default():\n",
    "    embedding=tf.Variable(tf.random_uniform((num_words, num_embedding), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding,inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define nagative sampling\n",
    "\n",
    "n_sampled = 200\n",
    "with train_graph.as_default():\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((n_vocab, num_embedding), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(n_vocab))\n",
    "    \n",
    "     # Calculate the loss using negative sampling\n",
    "    #loss = tf.nn.sampled_softmax_loss(softmax_w, softmax_b, \n",
    "                                      #labels, embed,\n",
    "                                      #n_sampled, n_vocab,partition_strategy=\"div\")\n",
    "            \n",
    "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")        \n",
    "    cost = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "\n",
    "\n",
    "with train_graph.as_default():\n",
    "    ## From Thushan Ganegedara's implementation\n",
    "    valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))\n",
    "    normalized_embedding = embedding / norm\n",
    "    valid_embedding = tf.nn.embedding_lookup(normalized_embedding, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embedding, tf.transpose(normalized_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "\n",
    "valid_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[4845] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "Caused by op 'nce_loss/embedding_lookup_1', defined at:\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-9e496c58d28a>\", line 13, in <module>\n",
      "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1241, in nce_loss\n",
      "    name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1074, in _compute_sampled_logits\n",
      "    biases, all_ids, partition_strategy=partition_strategy)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n",
      "    transform_fn=None)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n",
      "    result = _clip(array_ops.gather(params[0], ids, name=name),\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): indices[4845] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "indices[4420] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "Caused by op 'nce_loss/embedding_lookup_1', defined at:\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-9e496c58d28a>\", line 13, in <module>\n",
      "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1241, in nce_loss\n",
      "    name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1074, in _compute_sampled_logits\n",
      "    biases, all_ids, partition_strategy=partition_strategy)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n",
      "    transform_fn=None)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n",
      "    result = _clip(array_ops.gather(params[0], ids, name=name),\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): indices[4420] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1327] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "Caused by op 'nce_loss/embedding_lookup_1', defined at:\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-9e496c58d28a>\", line 13, in <module>\n",
      "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1241, in nce_loss\n",
      "    name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1074, in _compute_sampled_logits\n",
      "    biases, all_ids, partition_strategy=partition_strategy)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n",
      "    transform_fn=None)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n",
      "    result = _clip(array_ops.gather(params[0], ids, name=name),\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): indices[1327] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "indices[8970] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "Caused by op 'nce_loss/embedding_lookup_1', defined at:\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-9e496c58d28a>\", line 13, in <module>\n",
      "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1241, in nce_loss\n",
      "    name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1074, in _compute_sampled_logits\n",
      "    biases, all_ids, partition_strategy=partition_strategy)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n",
      "    transform_fn=None)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n",
      "    result = _clip(array_ops.gather(params[0], ids, name=name),\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): indices[8970] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 100 Avg. Training loss: 781.1411 0.3148 sec/batch\n",
      "indices[3247] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n",
      "Caused by op 'nce_loss/embedding_lookup_1', defined at:\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-9e496c58d28a>\", line 13, in <module>\n",
      "    loss = tf.nn.nce_loss(weights=softmax_w,biases=softmax_b,labels=labels,inputs=embed,num_sampled=n_sampled,num_classes=n_vocab, partition_strategy=\"div\")\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1241, in nce_loss\n",
      "    name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\", line 1074, in _compute_sampled_logits\n",
      "    biases, all_ids, partition_strategy=partition_strategy)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n",
      "    transform_fn=None)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n",
      "    result = _clip(array_ops.gather(params[0], ids, name=name),\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/shuhanLin/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): indices[3247] = 66501 is not in [0, 66501)\n",
      "\t [[Node: nce_loss/embedding_lookup_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@Adam/update_Variable_2/AssignSub\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_2/read, nce_loss/concat, nce_loss/embedding_lookup_1/axis)]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2f6fa7a85d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b3670b0d279e>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(word_index_list, batch_size, window_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_target_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5518d2947e9f>\u001b[0m in \u001b[0;36mget_target_words\u001b[0;34m(word_index_list, index, window_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtarget_word_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword_index_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_word_indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    iteration = 1\n",
    "    loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        batches = get_batches(trainning_word_index_list, batch_size, window_size)\n",
    "        start = time.time()\n",
    "\n",
    "   \n",
    "        for x, y in batches:\n",
    "            try:\n",
    "                feed = {inputs: x, labels: np.array(y)[:, None]}\n",
    "                train_loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "\n",
    "                loss += train_loss\n",
    "\n",
    "                if iteration % 100 == 0: \n",
    "                    end = time.time()\n",
    "                    print(\"Epoch {}/{}\".format(e, epochs),\n",
    "                          \"Iteration: {}\".format(iteration),\n",
    "                          \"Avg. Training loss: {:.4f}\".format(loss/100),\n",
    "                          \"{:.4f} sec/batch\".format((end-start)/100))\n",
    "                    loss = 0\n",
    "                    start = time.time()\n",
    "\n",
    "                if iteration % 1000 == 0:\n",
    "                    # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "                    sim = similarity.eval()\n",
    "                    for i in range(valid_size):\n",
    "                        valid_word = int_to_word[str(valid_examples[i])]\n",
    "                        top_k = 8 # number of nearest neighbors\n",
    "                        nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                        log = 'Nearest to %s:' % valid_word\n",
    "\n",
    "                        for k in range(top_k):\n",
    "                            close_word = int_to_word[str(nearest[k])]\n",
    "                            log = '%s %s,' % (log, close_word)\n",
    "                        print(log)\n",
    "\n",
    "                iteration = iteration +1\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                pass \n",
    "                \n",
    "                \n",
    "    save_path = saver.save(sess, \"checkpoints/text8.ckpt\")\n",
    "    embed_mat = sess.run(normalized_embedding)           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
